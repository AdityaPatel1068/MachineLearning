{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaPatel1068/MachineLearning/blob/main/Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmdZRaXJi3Cz"
      },
      "source": [
        "#<font color = 'blue'> **Assignment 5** </font>\n",
        "\n",
        "This assignment covers some basics of convolutional neural networks (CNNs) for image classification with PyTorch deep learning framework, including the implementation of convolution, max-pooling, and fully connected layers in CNNs with relu activation functions, normalization of the input data, optimization of the CNN model with cross entropy loss, the SGD (momentum = 0.9) optimizer, learning rate 0.001, batch size 256, and 100 epochs.\n",
        "\n",
        "- Since the CIFAR10 dataset is large, I would suggest all of you to run your code with GPU. See the last section about how to use GPU to train deep neural networks.\n",
        "\n",
        "The primary objective of this assignment is to deepen your understanding of CNN and familiarize you with key  Python libraries such as Numpy, Matplotlib, and PyTorch. Additionally, you will become more acquainted with implementing deep neural networks using PyTorch, specifically for the task of image classification in computer vision.\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "- Simple implementation of CNN model with two convolution layers, one pooling layer, three fully connected layers using PyTorch: https://colab.research.google.com/drive/17yGkfAKlPhj_tZRNR2jl7_PFCp0z1eTl?usp=drive_open#scrollTo=p00DiDzvfnLT\n",
        "\n",
        "<b>Note: </b> You must run/evaluate all cells. <b>Order of cell execution is important.<b>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color = 'blue'> **1.**  Load the CIFAR10 dataset with PyTorch.</font>\n",
        "\n",
        "Practice to use PyTorch to download CIFAR10 dataset, and build training and test dataloader with batch size = 256.\n",
        "\n",
        "<b>Answer</b>"
      ],
      "metadata": {
        "id": "TJIdAFVLaEYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoWC41s-iwbv",
        "outputId": "e87d349c-ee27-41e7-a1e7-961b280a0e41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|â–‹         | 11632640/170498071 [00:02<00:14, 11019513.42it/s]"
          ]
        }
      ],
      "source": [
        "# your code goes here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define CNN model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "# Use GPU for training\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(100): # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "2556ea3d-50f4-4bab-eaa3-84807469e689",
        "id": "ZWCsr85m365C"
      },
      "source": [
        "### <font color = 'blue'> **2.** Visualize random image samples in one minibatch.</font>\n",
        "\n",
        "# <b>Answer</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG_OP6qv365D"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "## Your code goes here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color = 'blue'> **3.** Define a CNN model\n",
        "\n",
        "The CNN model architecture are shown as follows (4 conv layers, 4 pooling layers, 2 fully connected layers).\n",
        "\n",
        "*conv1->pool1->conv2->pool2->conv3->pool3->conv4->pool4->FC1->FC2*\n",
        "\n",
        "Specifications of input and output dimensions, kernel sizes, stride, and padding across various layers:\n",
        "\n",
        "<code>\n",
        "\n",
        "**conv1**: input dim = 3, output dim = 64, kernel size 3, stride = 1, padding = 1\n",
        "\n",
        "**conv2**: input dim = 64, output dim = 128, kernel size 3, stride = 1, padding = 1\n",
        "\n",
        "**conv3**: input dim = 128, output dim = 256, kernel size 3, stride = 1, padding = 1\n",
        "\n",
        "**conv4**: input dim = 256, output dim = 512, kernel size 3, stride = 1, padding = 1\n",
        "\n",
        "**pool1**: kernel = 2, stride = 2\n",
        "\n",
        "**pool2**: kernel = 2, stride = 2\n",
        "\n",
        "**pool3**: kernel = 2, stride = 2\n",
        "\n",
        "**pool4**: kernel = 2, stride = 2\n",
        "\n",
        "**FC1**: input dim = 512 * 2 * 2, output dim = 1024\n",
        "\n",
        "**FC2**: input dim = 1024, output dim = 10\n",
        "\n",
        "</code>\n",
        "\n",
        "Note that, there is always a ReLU activation function applied after each conv layer before the max-pooling layers except for the last dense layer.\n",
        "\n",
        "Please refer to the colab code [here](https://colab.research.google.com/drive/17yGkfAKlPhj_tZRNR2jl7_PFCp0z1eTl?usp=drive_open#scrollTo=83IyYAGxfnLX)."
      ],
      "metadata": {
        "id": "ungTscFwz9gn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGaInazukQRP"
      },
      "outputs": [],
      "source": [
        "## Your code goes here\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color = 'blue'> **4.**  Training your customized CNN model.</font>\n",
        "\n",
        "Apply cross entropy loss, SGD optimizer with momentum = 0.9, batch size = 256, learning rate = 0.001,  epochs = 100."
      ],
      "metadata": {
        "id": "6UkHYB0tzfOq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N8p_WdsjZ0m"
      },
      "outputs": [],
      "source": [
        "# your code goes here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color = 'blue'> **5.** Prediction on test dataset\n",
        "- make prediction on test dataset\n",
        "- Output the test accuracy for each class\n",
        "\n",
        "<font>"
      ],
      "metadata": {
        "id": "_jk-CIlaPGxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your code goes here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IU6RHDidPqQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}